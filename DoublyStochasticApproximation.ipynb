{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doubly Stochastic Approximation\n",
    "\n",
    "A doubly stochastic matrix is a squared nonnegative matrix which every single row and every single column sum to one.  According to the Birkhoff-von Neumann theorem, DSMs form the Birkhoff polytope $\\mathbb{B}^{n}$ which is a convex hull for the set of $n \\times n$ permutation matrices. Consequently, it is natural to think of DSMs as relaxations of permutation matrices. In addition, DSMs are continuous which make them useful for gradient-based learners, differently from permutation matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=5, suppress=True)\n",
    "import matplotlib.pyplot as plt\n",
    "from cvxpy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "Therefore, **the goal of doubly stochastic approximation is to find the closest doubly stochastic matrix $Y \\in \\mathbb{B}^{n \\times n}$ from a given arbritary square matrix $X \\in \\mathbb{R}^{n \\times n}$**. We will use random matrices as Xs and introduce approximate and exact solutions for this problem. In order to measure the quality of the approximation, we will measure the average $\\ell_1\\text{-error}$ over rows and columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged DSM error for a random matrix: 20.07\n"
     ]
    }
   ],
   "source": [
    "# l1-Error\n",
    "def dsm_error(X):\n",
    "    e_rows = np.abs(1. - np.sum(X, axis=1))\n",
    "    e_cols = np.abs(1. - np.sum(X, axis=0))\n",
    "    return np.mean(np.append(e_rows, e_cols))\n",
    "\n",
    "# Random generated matrix\n",
    "X = np.random.rand(4,4) * 10\n",
    "print(\"Averaged DSM error for a random matrix: {:.2f}\".format(dsm_error(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sinkhorn Iterations\n",
    "\n",
    "According to the Sinkhorn theorem, if $X$ is an $n \\times n$ matrix with **strictly positive elements**, then there exist diagonal matrices $D_1$ and $D_2$ with strictly positive diagonal elements such that $D_1XD_2$ is doubly stochastic. In addition, Sinkhorn and Knopp introduced a simple iterative method to approach the double stochastic matrix by alternately rescaling all rows and all columns of $X$ to sum to 1. Therefore, a principled and efficient way to approximate DSMs is to make use of these theorems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random input:\n",
      "[[ 0.93816  0.31993]\n",
      " [ 0.04423  0.52943]]\n",
      "Sinkhorn Approx. DSM:\n",
      "[[ 0.85572  0.14454]\n",
      " [ 0.14428  0.85546]]\n"
     ]
    }
   ],
   "source": [
    "def sinkhorn(X, max_it=10):\n",
    "    Y = np.copy(X)\n",
    "    for it in range(max_it):\n",
    "        # Line multipliers normalizer\n",
    "        D1 = np.diagflat(1. / np.sum(Y, axis=1))\n",
    "        # Cols multipliers normalizer\n",
    "        D2 = np.diagflat(1. / np.sum(np.dot(D1, Y), axis=0))\n",
    "        # Normalize D1 Y D2\n",
    "        Y = np.dot(np.dot(D1, Y),D2)\n",
    "    return Y, D1, D2\n",
    "\n",
    "X = np.random.rand(2,2)\n",
    "Y, _, _ = sinkhorn(X)\n",
    "print(\"Random input:\\n{}\".format(X))\n",
    "print(\"Sinkhorn Approx. DSM:\\n{}\".format(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a better experiment: Create $NumTrials$ (e.g, 10) random matrix of size $n$, compute their approximated dsm using the sinkhorn algorithm, compute the approximation error and report a boxplot. Repeat this experiment for different matrices size (e.g, $n \\in [2, 10]$). As we can see below, the Sinkhorn normalization just need 10 iterations to reach almost perfect approximations. In addition, larger matrices makes the convergence even better.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAEPCAYAAAAJYmAlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzCwr/x+XgdRus8KXZAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f2ecba9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Experiment\n",
    "NumTrials, Nmax = 10, 10\n",
    "errors = np.ones((NumTrials, Nmax), dtype=np.float)\n",
    "for n in range(Nmax):\n",
    "    for trial in range(NumTrials):\n",
    "        X = np.random.rand(2+n, 2+n)\n",
    "        Y, _, _ = sinkhorn(X, max_it=10)\n",
    "        errors[trial, n] = dsm_error(Y)\n",
    "\n",
    "# Boxplot of dsm errors \n",
    "plt.boxplot(errors, labels=range(2, 2+Nmax), showmeans=True)\n",
    "plt.ylim([-1e-5,1e-5])\n",
    "plt.ylabel('AVG DSM Error')\n",
    "plt.xlabel('Matrix size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact Solution\n",
    "\n",
    "The DSM approximation problem can be described as,\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "& \\underset{Y \\in \\mathbb{R_+}^{n \\times n}}{\\text{minimize}}\n",
    "& & \\mid\\mid Y - X \\mid\\mid_F \\\\\n",
    "& \\text{subject to}\n",
    "& & \\mathbf{1^T} Y = \\mathbf{1} \\\\\n",
    "& & & Y \\mathbf{1} = \\mathbf{1} \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "where $\\mathbf{1}$ is a column vector of ones. This problem is convex and can be easily stated as a quadratic program by vectorizing the matrices and performing the change of variavle $z = vec(Y) - vec(x)$. However, we will let  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random input:\n",
      "[[ 0.74256  0.18086  0.66062]\n",
      " [ 0.2361   0.75894  0.68974]\n",
      " [ 0.33575  0.11498  0.79574]]\n",
      "Best Approx. DSM:\n",
      "[[ 0.61144  0.13629  0.25227]\n",
      " [ 0.0714   0.68079  0.24781]\n",
      " [ 0.31716  0.18293  0.49992]]\n"
     ]
    }
   ],
   "source": [
    "# DSM approx. as QP\n",
    "def dsm_qp(X):\n",
    "    Y = Variable(*X.shape)\n",
    "    obj = Minimize(norm(Y - X, 'fro'))\n",
    "    consts = [sum_entries(Y, axis=0) == 1, sum_entries(Y, axis=1) == 1, Y >= 0]\n",
    "    prob = Problem(obj, consts)\n",
    "    prob.solve()\n",
    "    return Y.value, prob.value\n",
    "\n",
    "X = np.random.rand(3,3)\n",
    "Y, _ = dsm_qp(X)\n",
    "print(\"Random input:\\n{}\".format(X))\n",
    "print(\"Best Approx. DSM:\\n{}\".format(Y))                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the problem is feasible, then the solution is the closest DSM to the given arbritary matrix. Different from the Sinkhorn approach, this method does not require any special structure in the input matrix, it can even have negative entries. However, it may be more computationally expensive than the Sinkhorn approach for large matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
